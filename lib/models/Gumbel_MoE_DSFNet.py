import torch
from torch import nn
import torch.nn.functional as F
import os
from copy import deepcopy

# å¯¼å…¥åŸå§‹çš„DSFNetä½œä¸ºæˆ‘ä»¬çš„â€œä¸“å®¶â€
from .DSFNet import DSFNet as DSFNet_expert
# å¯¼å…¥æ‚¨é¡¹ç›®ä¸­çš„ load_model å‡½æ•°
from .stNet import load_model
# å¯¼å…¥åˆ†å¸ƒå¼é€šä¿¡åº“ï¼Œè¿™æ˜¯æ–°forwardæ–¹æ³•æ‰€å¿…éœ€çš„
import torch.distributed as dist


class GumbelGatingNetwork(nn.Module):
    """
    ä½¿ç”¨Gumbel-Softmaxçš„é—¨æ§ç½‘ç»œï¼Œæ”¯æŒTop-Kä¸“å®¶é€‰æ‹©ã€‚
    - è®­ç»ƒæ—¶ä½¿ç”¨ Gumbel-Softmax å®ç°å¯¹Top-Kä¸ªä¸“å®¶çš„å¯å¯¼é€‰æ‹©ã€‚
    - è¯„ä¼°æ—¶ä½¿ç”¨ ArgMax å®ç°å¯¹Top-Kä¸ªä¸“å®¶çš„ç¡®å®šæ€§é€‰æ‹©ã€‚
    """

    def __init__(self, num_experts, top_k=1):
        """
        åˆå§‹åŒ–é—¨æ§ç½‘ç»œã€‚
        Args:
            num_experts (int): ä¸“å®¶æ€»æ•°ã€‚
            top_k (int): æ¯ä¸ªè¾“å…¥éœ€è¦æ¿€æ´»çš„ä¸“å®¶æ•°é‡ã€‚
        """
        super(GumbelGatingNetwork, self).__init__()
        self.num_experts = num_experts
        self.top_k = top_k

        # ä¸€ä¸ªè½»é‡çº§çš„CNNï¼Œç”¨äºä»è¾“å…¥ä¸­æå–ç‰¹å¾ä»¥å†³å®šä¸“å®¶æƒé‡
        self.backbone = nn.Sequential(
            # è¾“å…¥å½¢çŠ¶: [B, C*T, H, W], ä¾‹å¦‚ [B, 15, H, W]
            nn.Conv2d(3 * 5, 64, kernel_size=7, stride=2, padding=3, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # è¾“å‡ºç‰¹å¾å›¾å°ºå¯¸ H/4, W/4
        )
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Linear(64, self.num_experts)

    def forward(self, x):
        b, c, t, h, w = x.shape
        # å°†æ—¶é—´å’Œé€šé“ç»´åº¦åˆå¹¶ï¼Œä»¥é€‚åº”2Då·ç§¯: [B, C, T, H, W] -> [B, C*T, H, W]
        x_reshaped = x.view(b, c * t, h, w)

        features = self.backbone(x_reshaped)
        features = self.avg_pool(features)
        features = features.view(b, -1)

        # logits: [B, num_experts], æ¯ä¸ªä¸“å®¶çš„åŸå§‹åˆ†æ•°
        logits = self.fc(features)

        # é€‰å‡º Top-K çš„ä¸“å®¶ç´¢å¼•å’Œå¯¹åº”çš„åˆ†æ•°(logits)
        top_k_logits, top_k_indices = torch.topk(logits, self.top_k, dim=1)

        # åˆ›å»ºä¸€ä¸ªç”¨äºå­˜å‚¨é—¨æ§æƒé‡çš„ç¨€ç–å¼ é‡
        sparse_gates = torch.zeros_like(logits)

        if self.training:
            # è®­ç»ƒæ—¶: åœ¨ top-k çš„ logits ä¸Šåº”ç”¨ Gumbel-Softmax
            # hard=True ä¼šåœ¨å‰å‘ä¼ æ’­æ—¶äº§ç”Ÿ one-hot è¾“å‡ºï¼Œä½†åœ¨åå‘ä¼ æ’­æ—¶ä½¿ç”¨ softmax çš„æ¢¯åº¦
            gumbel_top_k = F.gumbel_softmax(top_k_logits, tau=1.0, hard=True, dim=-1)
            # å°† Gumbel-Softmax çš„ç»“æœï¼ˆè¿‘ä¼¼0/1ï¼‰æ”¾å›ç¨€ç–å¼ é‡çš„æ­£ç¡®ä½ç½®
            sparse_gates.scatter_(1, top_k_indices, gumbel_top_k)
        else:
            # è¯„ä¼°æ—¶: ç›´æ¥å°†è¢«é€‰ä¸­çš„ä¸“å®¶ä½ç½®èµ‹äºˆæƒé‡
            # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ 1.0 / self.top_kï¼Œå®ç°å¯¹ top-k ä¸ªä¸“å®¶çš„ç­‰æƒé‡å¹³å‡é›†æˆ
            sparse_gates.scatter_(1, top_k_indices, 1.0 / self.top_k)

        # è¾…åŠ©æŸå¤± (Load Balancing Loss)ï¼Œé¼“åŠ±é—¨æ§ç½‘ç»œå‡åŒ€åœ°ä½¿ç”¨æ‰€æœ‰ä¸“å®¶
        expert_mask = torch.zeros_like(logits).scatter_(1, top_k_indices, 1)
        density = expert_mask.mean(dim=0)
        density_proxy = F.softmax(logits, dim=1).mean(dim=0)
        aux_loss = (density * density_proxy).sum() * self.num_experts

        return sparse_gates, top_k_indices, aux_loss


class Gumbel_MoE_DSFNet(nn.Module):
    """
    ä½¿ç”¨Gumbel-Softmaxé—¨æ§è¿›è¡Œç«¯åˆ°ç«¯è®­ç»ƒçš„MoEæ¨¡å‹ã€‚
    æ”¯æŒé€‰æ‹© Top-K ä¸ªä¸“å®¶ï¼Œå¹¶ä½¿ç”¨ç¨€ç–è®¡ç®—ä»¥èŠ‚çœæ˜¾å­˜ã€‚
    """

    def __init__(self, heads, head_conv=128, num_experts=3, top_k=1, loss_coef=1e-2,
                 pretrained_paths=None, expert_modules=None):
        super(Gumbel_MoE_DSFNet, self).__init__()
        self.num_experts = num_experts
        self.top_k = top_k
        self.loss_coef = loss_coef
        self.heads = heads

        print(f"ğŸš€ åˆå§‹åŒ– Gumbel-MoE-DSFNet æ¨¡å‹ (Top-K={self.top_k})")
        print(f"   - é—¨æ§æœºåˆ¶: è®­ç»ƒæ—¶ Top-K Gumbel-Softmax, è¯„ä¼°æ—¶ Top-K ArgMax")
        print(f"   - ä¸“å®¶æ€»æ•°: {self.num_experts}")

        self.gating_network = GumbelGatingNetwork(self.num_experts, self.top_k)

        if expert_modules is not None:
            print("   - ä½¿ç”¨å¤–éƒ¨æä¾›çš„ä¸“å®¶æ¨¡å—åˆ—è¡¨ã€‚")
            if len(expert_modules) != self.num_experts:
                raise ValueError(f"æä¾›çš„ä¸“å®¶æ¨¡å—æ•°é‡({len(expert_modules)})ä¸num_experts({self.num_experts})ä¸åŒ¹é…ã€‚")
            self.experts = expert_modules
        elif pretrained_paths is not None:
            print("   - æ ¹æ®è·¯å¾„åˆ—è¡¨åˆ›å»ºå¹¶åˆå§‹åŒ–ä¸“å®¶ã€‚")

            # --- [æ ¸å¿ƒä¿®å¤: å¥å£®çš„ä¸“å®¶åˆå§‹åŒ–é€»è¾‘] ---
            self.experts = nn.ModuleList()
            base_experts = []

            # 1. é¦–å…ˆåŠ è½½æ‰€æœ‰åŸºç¡€çš„é¢„è®­ç»ƒä¸“å®¶
            for i, path in enumerate(pretrained_paths):
                print(f"   - åŠ è½½åŸºç¡€ä¸“å®¶ {i + 1}/{len(pretrained_paths)} ä»: '{os.path.basename(path)}'")
                expert_model = DSFNet_expert(heads, head_conv)
                if os.path.exists(path):
                    expert_model = load_model(expert_model, path)
                else:
                    print(f"   - âš ï¸ è­¦å‘Š: è·¯å¾„ä¸å­˜åœ¨ {path}ã€‚ä¸“å®¶å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–æƒé‡ã€‚")
                base_experts.append(expert_model)

            if not base_experts:
                raise ValueError("é¢„è®­ç»ƒè·¯å¾„åˆ—è¡¨ä¸ºç©ºæˆ–æ‰€æœ‰è·¯å¾„å‡æ— æ•ˆï¼Œæ— æ³•åˆ›å»ºä¸“å®¶ã€‚")

            # 2. é€šè¿‡å¤åˆ¶åŸºç¡€ä¸“å®¶æ¥å¡«æ»¡ expert_list è‡³ num_experts çš„æ•°é‡
            for i in range(self.num_experts):
                # è½®æµä» base_experts ä¸­é€‰å–ä¸€ä¸ªè¿›è¡Œå¤åˆ¶
                base_to_copy = base_experts[i % len(base_experts)]
                self.experts.append(deepcopy(base_to_copy))
            # --- [ä¿®å¤ç»“æŸ] ---

        else:
            raise ValueError("å¿…é¡»æä¾› 'pretrained_paths' æˆ– 'expert_modules'ã€‚")

        print(f"âœ… æ‰€æœ‰ {len(self.experts)} ä¸ªä¸“å®¶æ¨¡å—å·²è®¾ç½®ã€‚")

    def forward(self, x):
        """
        é«˜æ•ˆçš„ã€ç¨€ç–è®¡ç®—çš„å‰å‘ä¼ æ’­æ–¹æ³•ã€‚
        """
        # 1. ä»é—¨æ§ç½‘ç»œè·å–ç¨€ç–æƒé‡å’Œè¢«é€‰ä¸­çš„ä¸“å®¶ç´¢å¼•
        sparse_gates, top_k_indices, aux_loss = self.gating_network(x)

        batch_size = x.shape[0]

        # 2. åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„è¾“å‡ºå¼ é‡å­—å…¸
        with torch.no_grad():
            dummy_output = self.experts[0](x)[0]
        final_outputs = {head: torch.zeros(batch_size, *dummy_output[head].shape[1:], device=x.device) for head in
                         self.heads}

        # 3. éå†æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬ï¼Œåªè®¡ç®—è¢«æ¿€æ´»çš„ä¸“å®¶
        for i in range(batch_size):
            # è·å–å½“å‰æ ·æœ¬é€‰æ‹©çš„ä¸“å®¶ç´¢å¼• (ä¾‹å¦‚: [2, 7, 11] for top_k=3)
            active_indices = top_k_indices[i]
            # è·å–å½“å‰æ ·æœ¬çš„è¾“å…¥ï¼Œå¹¶ä¿æŒæ‰¹æ¬¡ç»´åº¦ä¸º1
            sample_input = x[i].unsqueeze(0)

            # è·å–å½“å‰æ ·æœ¬å¯¹åº”çš„é—¨æ§æƒé‡ (ä¾‹å¦‚: [0.0, 1.0, 0.0, ..., 1.0, ..., 1.0, ...])
            active_gates = sparse_gates[i][active_indices]

            # 4. éå†è¢«æ¿€æ´»çš„kä¸ªä¸“å®¶
            for k in range(self.top_k):
                expert_idx = active_indices[k].item()
                gate_val = active_gates[k]

                if gate_val == 0:
                    continue

                # åªè®¡ç®—è¿™ä¸ªè¢«æ¿€æ´»çš„ä¸“å®¶çš„è¾“å‡º
                expert_output_dict = self.experts[expert_idx](sample_input)[0]

                # ä½¿ç”¨é—¨æ§æƒé‡å¯¹ä¸“å®¶çš„è¾“å‡ºè¿›è¡ŒåŠ æƒï¼Œå¹¶ç´¯åŠ åˆ°æœ€ç»ˆç»“æœä¸­
                for head_name, head_tensor in expert_output_dict.items():
                    final_outputs[head_name][i] += gate_val * head_tensor.squeeze(0)

        # 5. è¿”å›æœ€ç»ˆçš„é¢„æµ‹ç»“æœå’Œç”¨äºè®­ç»ƒçš„è¾…åŠ©æŸå¤±
        return [final_outputs], self.loss_coef * aux_loss