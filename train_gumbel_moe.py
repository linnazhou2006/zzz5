from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import torch
import torch.utils.data
from torch import nn
from copy import deepcopy

# --- Distributed Training Imports ---
import torch.distributed as dist
from torch.utils.data.distributed import DistributedSampler
from torch.distributed.fsdp import FullyShardedDataParallel as FSDP
from torch.distributed.fsdp.wrap import wrap
import json
import json
# --- Project-specific Imports ---
from lib.utils.opts import opts
from lib.utils.logger import Logger
from lib.models.stNet import save_model
from lib.models.DSFNet import DSFNet as DSFNet_expert
from lib.models.Gumbel_MoE_DSFNet import Gumbel_MoE_DSFNet
from lib.dataset.coco_rsdata import COCO
from lib.Trainer.ctdet import CtdetTrainer


def perturb_model_weights(model, noise_level=1e-4):
    """
    å¯¹æ¨¡å‹çš„æ‰€æœ‰å¯è®­ç»ƒæƒé‡å’Œåç½®æ·»åŠ ä¸€ä¸ªå°çš„éšæœºé«˜æ–¯å™ªå£°ã€‚
    """
    with torch.no_grad():
        for param in model.parameters():
            if param.requires_grad:
                noise = torch.randn_like(param) * noise_level
                param.add_(noise)
    return model


def setup(opt):
    """
    ä½¿ç”¨ç”± torchrun æä¾›çš„ç¯å¢ƒå˜é‡åˆå§‹åŒ–åˆ†å¸ƒå¼è¿›ç¨‹ç»„ã€‚
    """
    rank = int(os.environ['RANK'])
    world_size = int(os.environ['WORLD_SIZE'])
    local_rank = int(os.environ['LOCAL_RANK'])

    dist.init_process_group("nccl")
    torch.cuda.set_device(local_rank)
    opt.local_rank = local_rank
    return rank, world_size


def main(opt):
    """
    ä¸»è®­ç»ƒå‡½æ•°ï¼Œç”±æ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹æ‰§è¡Œã€‚
    """
    rank, world_size = setup(opt)
    logger = Logger(opt) if rank == 0 else None

    torch.manual_seed(opt.seed + rank)

    DataTrain = COCO(opt, 'train')
    train_sampler = DistributedSampler(DataTrain, num_replicas=world_size, rank=rank)
    train_loader = torch.utils.data.DataLoader(
        DataTrain, batch_size=opt.batch_size, shuffle=False,
        num_workers=opt.num_workers, pin_memory=True, drop_last=True, sampler=train_sampler
    )

    val_loader = None
    if rank == 0:
        DataVal = COCO(opt, 'test')
        val_loader = torch.utils.data.DataLoader(
            DataVal, batch_size=1, shuffle=False,
            num_workers=opt.num_workers, pin_memory=True
        )

    dist.barrier()

    print(f"[Rank {rank}] Creating model...")
    head = {'hm': DataTrain.num_classes, 'wh': 2, 'reg': 2}
    head_conv = 128

    # ==================== [æ ¸å¿ƒ: 18ä¸“å®¶åˆå§‹åŒ–é…æ–¹] ====================
    num_experts_target = 18
    TOP_K_VALUE = 4

    base_pretrained_paths = {
        's1': './checkpoint/DSFNet_s1.pth',
        's2': './checkpoint/DSFNet_s2.pth',
        's3': './checkpoint/DSFNet_s3.pth',
        's4': './checkpoint/DSFNet_s4.pth'
    }
    perturbation_recipe = {'s1': 4, 's2': 4, 's3': 4, 's4': 2}

    if rank == 0:
        print(f"ğŸš€ åˆå§‹åŒ– {num_experts_target} ä¸ªä¸“å®¶çš„MoEæ¨¡å‹...")

    expert_list = nn.ModuleList()
    loaded_base_experts = {}

    for name, path in base_pretrained_paths.items():
        base_expert = DSFNet_expert(head, head_conv)
        if os.path.exists(path):
            from lib.models.stNet import load_model
            base_expert = load_model(base_expert, path)
            if rank == 0: print(f"   - æˆåŠŸåŠ è½½åŸºç¡€æƒé‡: {os.path.basename(path)}")
        else:
            if rank == 0: print(f"   - âš ï¸ è­¦å‘Š: è·¯å¾„ä¸å­˜åœ¨ {path}ã€‚")
        loaded_base_experts[name] = base_expert

    for name in ['s1', 's2', 's3', 's4']:
        if name in loaded_base_experts:
            expert_list.append(deepcopy(loaded_base_experts[name]))

    for name, num_copies in perturbation_recipe.items():
        if name in loaded_base_experts:
            base_expert_to_copy = loaded_base_experts[name]
            for _ in range(num_copies):
                #expert_list.append(deepcopy(perturb_model_weights(base_expert_to_copy)))
                # åˆ›å»ºä¸€ä¸ªæ·±åº¦æ‹·è´ï¼Œä½†ä¸è¿›è¡Œæƒé‡æ‰°åŠ¨
                replicated_expert = deepcopy(base_expert_to_copy)
                # Oringinal line: perturbed_expert = perturb_model_weights(perturbed_expert, noise_level=1e-4)
                expert_list.append(replicated_expert)
                # ====================================================

    if len(expert_list) != num_experts_target:
        raise ValueError(f"ä¸“å®¶åˆ›å»ºå¤±è´¥ï¼æœŸæœ› {num_experts_target}ï¼Œå®é™… {len(expert_list)}")

    if rank == 0: print(f"âœ… æˆåŠŸåˆ›å»ºå¹¶åˆå§‹åŒ–äº† {len(expert_list)} ä¸ªä¸“å®¶ã€‚")

    model = Gumbel_MoE_DSFNet(
        heads=head, head_conv=head_conv, num_experts=num_experts_target,
        top_k=TOP_K_VALUE, expert_modules=expert_list
    )
    # ==========================================================================

    # ==================== [æ ¸å¿ƒä¿®æ­£: å·®åˆ†å­¦ä¹ ç‡] ====================
    expert_lr = opt.lr * 0.05
    if rank == 0:
        print(f"Setting up optimizer with differential learning rates:")
        print(f"  - Gating Network LR: {opt.lr}")
        print(f"  - Experts LR: {expert_lr}")

    # åœ¨æ¨¡å‹è¢«FSDPåŒ…è£…ä¹‹å‰å®šä¹‰å‚æ•°ç»„
    params_to_optimize = [
        {'params': model.gating_network.parameters(), 'lr': opt.lr},
        {'params': model.experts.parameters(), 'lr': expert_lr}
    ]
    # =================================================================

    # å°†æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡ï¼Œç„¶åè¿›è¡Œæ‰‹åŠ¨åŒ…è£…
    model = model.to(rank)

    print(f"[Rank {rank}] Manually wrapping {len(model.experts)} expert modules for FSDP...")
    for i, expert_layer in enumerate(model.experts):
        model.experts[i] = wrap(expert_layer)

    fsdp_model = FSDP(model)
    print(f"[Rank {rank}] Model wrapped with FSDP using manual wrapping.")

    # ä½¿ç”¨é¢„å…ˆå®šä¹‰å¥½çš„å‚æ•°ç»„æ¥åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam(params_to_optimize)

    start_epoch = 0
    if opt.load_model != '' and opt.resume:
        # --- [æ ¸å¿ƒä¿®æ­£: PyTorch 1.11.0 åˆ†ç‰‡åŠ è½½é€»è¾‘] ---
        if not os.path.isdir(opt.load_model):
            raise ValueError("For FSDP resume, --load_model must be a directory containing sharded checkpoints.")

        if rank == 0:
            print(f"Loading FSDP sharded checkpoint from directory: {opt.load_model}")

        # 1. æ¯ä¸ªè¿›ç¨‹åŠ è½½è‡ªå·±çš„åˆ†ç‰‡æ–‡ä»¶
        shard_file = os.path.join(opt.load_model, f"shard_rank_{rank}.pth")
        if not os.path.exists(shard_file):
            raise FileNotFoundError(f"Shard file not found for rank {rank}: {shard_file}")

        sharded_state_dict = torch.load(shard_file, map_location="cpu")

        # 2. åŠ è½½çŠ¶æ€å­—å…¸
        fsdp_model.load_state_dict(sharded_state_dict)

        # 3. Rank 0 åŠ è½½å…ƒæ•°æ®æ¥æ¢å¤ epoch
        if rank == 0:
            meta_path = os.path.join(opt.load_model, "meta.json")
            if os.path.exists(meta_path):
                with open(meta_path, "r") as f:
                    meta_data = json.load(f)
                start_epoch = meta_data.get('epoch', 0)
                print(f"Resuming from epoch {start_epoch}.")
            else:
                print("Warning: meta.json not found. Resuming from epoch 0.")

        # å°† start_epoch å¹¿æ’­ç»™æ‰€æœ‰è¿›ç¨‹
        epoch_tensor = torch.tensor([start_epoch], dtype=torch.int64, device=rank)
        dist.broadcast(epoch_tensor, src=0)
        start_epoch = epoch_tensor.item()
        # --- [ä¿®æ­£ç»“æŸ] ---
    dist.barrier()

    trainer = CtdetTrainer(opt, fsdp_model, optimizer)
    trainer.set_device(opt.gpus, rank)

    print(f'[Rank {rank}] Starting training...')
    best = -1
    for epoch in range(start_epoch + 1, opt.num_epochs + 1):
        train_sampler.set_epoch(epoch)
        log_dict_train, _ = trainer.train(epoch, train_loader)

        # ==================== [ æ ¸å¿ƒä¿®æ­£ ] ====================
        # save_model å¿…é¡»ç”±æ‰€æœ‰è¿›ç¨‹è°ƒç”¨ï¼Œä»¥ä¾¿æ¯ä¸ªè¿›ç¨‹éƒ½èƒ½ä¿å­˜è‡ªå·±çš„åˆ†ç‰‡ã€‚
        # æˆ‘ä»¬å°†å®ƒä» "if rank == 0" å—ä¸­ç§»å‡ºã€‚

        # 1. æ‰€æœ‰è¿›ç¨‹éƒ½è°ƒç”¨ save_model æ¥ä¿å­˜æœ€æ–°çš„æ¨¡å‹
        #    å‡½æ•°å†…éƒ¨ä¼šå¤„ç† rank 0 çš„ç‰¹æ®Šé€»è¾‘ï¼ˆå¦‚åˆ›å»ºç›®å½•å’Œå†™metaæ–‡ä»¶ï¼‰
        save_dir_last = os.path.join(opt.save_weights_dir, 'model_last')
        save_model(save_dir_last, epoch, fsdp_model, optimizer)

        # 2. æ—¥å¿—è®°å½•å’ŒéªŒè¯ä»ç„¶åªåœ¨ rank 0 ä¸Šè¿›è¡Œ
        if rank == 0:
            logger.write(f'epoch: {epoch} |')
            # æ³¨æ„ï¼šä¸Šé¢çš„ save_model è°ƒç”¨å·²ç»è¢«ç§»å‡º
            for k, v in log_dict_train.items():
                logger.write(f'{k} {v:8f} | ')

            if opt.val_intervals > 0 and epoch % opt.val_intervals == 0:
                with torch.no_grad():
                    log_dict_val, _, stats = trainer.val(epoch, val_loader, DataVal.coco, DataVal)
                for k, v in log_dict_val.items():
                    logger.write(f'{k} {v:8f} | ')
                if log_dict_val['ap50'] > best:
                    best = log_dict_val['ap50']
                    print(f"\n[Rank 0] New best model found! Saving model_best...")
                    # åŒæ ·ï¼Œæ‰€æœ‰è¿›ç¨‹éƒ½éœ€è¦è°ƒç”¨ save_model
                    save_dir_best = os.path.join(opt.save_weights_dir, 'model_best')
                    save_model(save_dir_best, epoch, fsdp_model)

            logger.write('\n')

        # 3. åœ¨æ‰€æœ‰æ“ä½œï¼ˆåŒ…æ‹¬å¯èƒ½çš„ best model ä¿å­˜ï¼‰ä¹‹åè¿›è¡ŒåŒæ­¥
        #    è¿™ä¸ª barrier ç°åœ¨æ˜¯å¯é€‰çš„ï¼Œå› ä¸º save_model å†…éƒ¨å·²ç»æœ‰ barrier
        dist.barrier()
        # =========================================================

        if epoch in opt.lr_step:
            lr_new = opt.lr * (0.1 ** (opt.lr_step.index(epoch) + 1))
            expert_lr_new = expert_lr * (0.1 ** (opt.lr_step.index(epoch) + 1))
            if rank == 0:
                print(f'Drop LR to Gating: {lr_new}, Experts: {expert_lr_new}')

            optimizer.param_groups[0]['lr'] = lr_new
            optimizer.param_groups[1]['lr'] = expert_lr_new

    if rank == 0 and logger is not None:
        logger.close()
    dist.destroy_process_group()


if __name__ == '__main__':
    opts_parser = opts()
    opt = opts_parser.parse()
    opt.model_name = 'Gumbel_MoE_18_Experts'
    opt = opts_parser.init(opt)

    main(opt)